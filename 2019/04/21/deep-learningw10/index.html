<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python," />





  <link rel="alternate" href="/atom.xml" title="DesmonDay's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="第10周-卷积神经网络">
<meta property="og:url" content="https://github.com/DesmonDay/2019/04/21/deep-learningw10/index.html">
<meta property="og:site_name" content="DesmonDay&#39;s Blog">
<meta property="og:description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2132ecef254524fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-24c5a8a203e46666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e5d257063b772320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4d3c64a43489e39c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-dc8899bc8d386eb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-b8a90a6aa25f7d62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-6bc7d0ef4bca22c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2fa4f586983b3583.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8f5daa4b3c5c6794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-51dbad653021f2cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-45c74100fa75f632.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-ebe1f304259697e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e7d237be92bbae53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8979cfce84796e30.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-0022fc160f42e86e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d8b67dbf0004c314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a17259e83c0465e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-84bdc3ef5cc59e88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8871e610b35fba21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e9601faf7c8e6030.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d66f4cdd25a87444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-af5878b975293364.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-aff45991e5b60ae2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-7c18e494b51a7d40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-3abb380561e76211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4099faae498d0270.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a0ac14e4a54ed0e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-c27afbd37be9239b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d0b784321e478e03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-280ea14a37187b24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-bfc3ed93735c4ff3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4fa87e9a9864a40a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-835c64616af3c9e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-99be17573b85d6a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2271c5e0b5e7e42e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-231d3cf598eae81f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-21b37e65798b205e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4677b61194940de7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-289b4ce9132362e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-74c0755a088a3f93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-01db157ba4575af2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-290ddcd54592a0bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-f80e3c253904cc19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-af95572a5883cc17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-ecd1fa2389d4ad7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-7a65120579fbb54b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8c14793776391c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2019-04-22T07:32:05.057Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第10周-卷积神经网络">
<meta name="twitter:description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/DesmonDay/2019/04/21/deep-learningw10/"/>





  <title>第10周-卷积神经网络 | DesmonDay's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DesmonDay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一只小辣鸡的自我拯救之路</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/DesmonDay/2019/04/21/deep-learningw10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DesmonDay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DesmonDay's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第10周-卷积神经网络</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-21T02:27:39+08:00">
                2019-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>接下来的四周为计算机视觉——卷积神经网络的内容。</p>
<h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><p>常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2132ecef254524fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参数大小将会非常巨大，并且对内存的要求也很高。为了解决这种情况，我们使用的神经网络实际上为卷积神经网络。</p>
<h1 id="卷积运算：边缘检测示例"><a href="#卷积运算：边缘检测示例" class="headerlink" title="卷积运算：边缘检测示例"></a>卷积运算：边缘检测示例</h1><p>卷积运算是卷积神经网络的最基本的组成部分，我们使用边缘检测作为入门样例，了解卷积是如何进行计算的。</p>
<p>在进行图像识别的时候，我们会进行边缘检测，示例如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-24c5a8a203e46666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>如何在图像中检测这些边缘？下面举一个例子：我们给出一个6x6的灰度图像（因此只有一个颜色通道），也就是6x6x1的矩阵。为了检测图像中的垂直边缘，我们可以构造一个3x3的矩阵称为过滤器（又称卷积核，一般为3x3矩阵），再将图像矩阵与这个过滤矩阵做卷积运算。这个卷积运算的输出为4x4的矩阵。具体如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e5d257063b772320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>可以看到，我们按顺序移动蓝色方块，再将方块中的数字与卷积核进行计算，计算的方法即对应元素相乘后再相加，得到的结果再写入结果矩阵对应的位置中。因此，在左上角的蓝色方块中，我们的计算为3x1+1x1+2x1+0x0+5x0+7x0+1x)-1+8x(-1)+2x(-1)=-5，其他结果也一样通过这种方式获得。</p>
<p>卷积运算在python中为conv_forward，在tensorflow中为tf.nn.conv2d，在Keras框架中为Conv2D。几乎所有的编程框架都有提供一些函数来实现卷积运算。</p>
<p>用简单例子解释为何这种运算可以这样计算：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4d3c64a43489e39c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以发现，我们的图像中间有着一个明显的垂直直线，这条垂直线是从黑到白的过滤线。当用一个3x3过滤器进行卷积运算时，这个3x3过滤器可视为左边有明亮像素，中间有过渡(0)，右边有深色像素的图例。通过卷积运算后，我们的矩阵对应的图像，在中间有段明亮的区域，这可以对应检查到这个6x6图像中间的垂直边缘。（这里的维数有些不正确，即检测到的边缘过粗，这是因为在此例中的图片过小，当我们使用的是1000x1000的图像，会发现其能很好地检测图像中的垂直边缘。）通过这种卷积运算，我们可以发现图像中的垂直边缘。</p>
<h1 id="更多边缘检测内容"><a href="#更多边缘检测内容" class="headerlink" title="更多边缘检测内容"></a>更多边缘检测内容</h1><p>在本节中，我们会学习如何区分正边和负边（即由亮到暗与由暗到亮的区别），也就是边缘的过渡。我们也可以了解到其他类型的边缘检测以及如何实现这些算法。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8636110-dc8899bc8d386eb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>对比发现，上图为由亮到暗的过渡，而下图为由暗到亮的过渡。也就是说，中间的这个3x3卷积核能够帮助我们区分正边和负边。</p>
<h2 id="Vertical-and-Horizontal-Edge-Detection"><a href="#Vertical-and-Horizontal-Edge-Detection" class="headerlink" title="Vertical and Horizontal Edge Detection"></a>Vertical and Horizontal Edge Detection</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-b8a90a6aa25f7d62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>左边的卷积核针对垂直边缘，而右边的卷积核针对水平边缘。另外，我们可以通过上图的一个例子来验证水平边缘的检测正确性。在右边用橙色框出来的10，表明其左边为亮，右边为暗，对应着原图像的上面过渡部分，其他的值也可以这么对应分析。</p>
<p>总而言之，通过使用不同的滤波器，我们可以找出垂直的或者水平的边缘。但事实上，对于这个3x3的卷积核来说，我们只使用了其中一种数字组合。在计算机视觉的文献中，曾争论过怎样的数字组合猜是最好的。<br>1、Sobel过滤器，它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-6bc7d0ef4bca22c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>2、 Scharr过滤器，它有着和之前完全不同的特性，但实际上也是一钟垂直边缘检测，如果将其旋转90度，可以得到对应水平边缘检测。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2fa4f586983b3583.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>随着<strong>深度学习</strong>的发展，当我们真正想去检测出复杂图像的边缘，也许我们不需要使用研究者选择的数字，而是可以<strong>把这些数字当成参数</strong>，通过<strong>后向传播</strong>算法来得到对应值。相比垂直和水平边缘，这种方法也可以检验包括其他方向的边缘。将卷积核的所有数字设置为参数，通过数据反馈，让神经网络自动学习，我们会发现神经网络可以学习一些低级的特征，比如边缘的特征。构成这些计算的基础是卷积运算，因此使得反向传播算法能够让神经网络学习任何它所需要的3x3过滤器，并在整幅图片上应用它，输出它所检测的特征。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8f5daa4b3c5c6794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h1><p>在卷积神经网络中，一个基本的卷积操作就是padding。</p>
<p>在之前我们在做卷积运算示例中，我们的输出矩阵为4x4维度，这是因为我们使用的过滤器在原图片上只可能有4x4种可能的位置。对应的，如果我们有nxn的图像，而过滤器为fxf，那么输出结果的维度为(n-f+1)x(n-f+1)。这样做有两个缺点，一是每次做卷积操作，我们的图像会缩小，比如从6x6到4x4，如果再多几次卷积运算，那么我们的图像就会变得很小了；二是如果我们注意到角落边的像素，这个像素点只被一个输出使用，因为它只位于一个3x3区域的一角，但如果是在中间的像素点，那么会有很多3x3区域重叠。因此那些在角落或者边缘区域的像素点在输出中采用较少，意味着我们丢掉了图像边缘位置的许多信息。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-51dbad653021f2cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>为了解决这两个问题，一是输出缩小，二是图像边缘的大部分信息丢失，我们可以在卷积操作之前对图像进行填充。例如，对上述图像进行填充，由6x6变为了8x8，那么我们得到的输出和原始图像一样，都是6x6的图像。通常，我们用进行填充。如果p是填充的数量，那么在本例中，p=padding=1，那么输出就变为了(n+2p-f+1)x(n+2p-f+1)。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-45c74100fa75f632.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>通过填充，位于角落或图像边缘的信息发挥作用较小的缺点就被削弱了。如果我们想再增加像素填充，则可以得到p=2之类的填充后的图像，如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-ebe1f304259697e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Valid-and-Same-convolutions"><a href="#Valid-and-Same-convolutions" class="headerlink" title="Valid and Same convolutions"></a>Valid and Same convolutions</h2><p>至于填充多少像素，通常有两个选择，分别称为Valid卷积和Same卷积。Valid卷积意味着没有padding；而另一个Same卷积，这个方法意味着我们填充图像后，输出大小和原图像的大小是一样的，具体的计算过程见下图：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e7d237be92bbae53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>另外注意到，在计算机视觉的惯例中，<strong>f通常是奇数</strong>。原因一是奇数才可以保证对称的填充；二是计算机视觉通常需要一个中心位置，便于指出过滤器的位置。</p>
<h1 id="卷积步长：Strided-convolutions"><a href="#卷积步长：Strided-convolutions" class="headerlink" title="卷积步长：Strided convolutions"></a>卷积步长：Strided convolutions</h1><p>卷积步长是另一个构建卷积神经网络的基本操作，下面我们举例解释卷积步长的含义。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8979cfce84796e30.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在本例中，我们设置Stride=2。先计算第一个位置的输出：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-0022fc160f42e86e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>接下来，要计算下一个位置的输出。由于卷积步长为2，因此我们不像之前一样将3x3区域往右移动一位，而是移动两位进行计算，如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d8b67dbf0004c314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>继续右移两个单位：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a17259e83c0465e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当我们要移动到下一行的时候，我们的步长也是2，因此下一个位置如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-84bdc3ef5cc59e88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>等等等。最后得到的输出为：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8871e610b35fba21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>因此输入输出的维度由以下公式决定：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e9601faf7c8e6030.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>注意到，如果商不是整数，在这种情况下我们可以向下取整。这个原则实现的方式是，你只在蓝框完全包括在图像或填充完的图像内部时，才对它进行运算。如果有的蓝框移动到了图像外部，那么我们不对其进行运算。也就是说，我们的3x3过滤器必须处于图像中或者填充之后的图像区域内，因此要向下取整。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d66f4cdd25a87444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Summary-of-convolutions"><a href="#Summary-of-convolutions" class="headerlink" title="Summary of convolutions"></a>Summary of convolutions</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-af5878b975293364.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Technical-note-on-cross-correlation-vs-convolution"><a href="#Technical-note-on-cross-correlation-vs-convolution" class="headerlink" title="Technical note on cross-correlation vs. convolution"></a>Technical note on cross-correlation vs. convolution</h2><p>这里讲解一个关于互相关和卷积的技术性建议，这不会影响到我们构建卷积神经网络的方式。如果我们看的是一本典型的数学教科书，那么卷积的定义是做元素乘积求和，实际上还有一个步骤是我们首先要做的，也就是在把这个6x6矩阵和3x3的过滤器卷积前，首先将3x3的过滤器沿水平和垂直轴翻转（先顺时针旋转90度，再水平翻转），用得到的矩阵来做元素相乘求和的操作。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-aff45991e5b60ae2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>从技术上讲，这个操作被称为互相关。在深度学习领域中，有很多人把它叫做卷积运算，但我们通常不需要用到翻转的步骤。事实证明在信号处理货某些数学分支中，卷积的定义包含翻转，使得卷积运算符拥有(A*B)*C=A*(B*C)的结合律性质。这对于一些信号处理应用来说很好，但对深度神经网络而言并不重要，因此我们忽略了这个双重镜像操作，从而简化代码。</p>
<p>综上所述，我们学习了如何进行卷积、如何使用填充、如何在卷积中选择步长，但我们目前为止使用的是关于矩阵的卷积。接下来会讲解如何对立体进行卷积。</p>
<h1 id="三维卷积：Convolutions-volumes"><a href="#三维卷积：Convolutions-volumes" class="headerlink" title="三维卷积：Convolutions volumes"></a>三维卷积：Convolutions volumes</h1><p>本节讲解如何在三维立体上进行卷积运算。假设我们想要检测RGB彩色图像的特征，即具有三个颜色通道。因此其维度为6x6x3，因此过滤器也需要是3x3x3的维度：（高、宽、通道个数）<br><img src="https://upload-images.jianshu.io/upload_images/8636110-7c18e494b51a7d40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>接下来研究背后的细节。其实实际的计算过程与二维的也很类似，我们将过滤器当做一个正方体，放置到原三维图像上，然后将这27个数字对应相乘和相加，填入输出的对应位置即可：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-3abb380561e76211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>再将立方体往右移一个单位，得到下一位，等等等，直到到达最后一位。</p>
<p>那么这个过滤器的作用是什么？举个例子，这个过滤器是3x3x3的，如果我们想检测图像红色通道的垂直边缘，而不关心其他通道，那么可以将三个过滤器分别设置如下后，再进行堆叠：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4099faae498d0270.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当然，如果我们想检测所有通道的垂直边缘，则可以使用这样的过滤器。因此，参数的不同选择，可以得到不同的过滤器。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a0ac14e4a54ed0e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>按照计算机视觉的惯例，当你的输入有特定的高宽和通道数时，我们的过滤器可以有不同的高，不同的宽，但是通道数必须相同。现在，我们了解了如何对立方体卷积，那么，如果我们想要同时检测垂直边缘和水平边缘，以及其他方向的边缘应该怎么做？换句话说，想同时使用多个过滤器，应该怎么办？</p>
<p>假设我们同时使用水平过滤器和垂直过滤器，过程如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-c27afbd37be9239b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>简单来说，我们得到的输出也成为了一个三维立体，这样就是同时两用了多个过滤器。</p>
<p>下面对维度进行总结：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d0b784321e478e03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>即输入的彩色图像为nxnxn_c，过滤器为fxfxn_c，这里n_c为通道数目，那么输出的维度为(n-f+1)x(n-f+1)xn_c’，这里n_c’指所应用的过滤器数目，即输出的通道数等于我们要检测的特征数。比如对前面的同时使用水平过滤器和垂直过滤器来说，n_c’=2。另外，这个式子默认我们没有使用padding。</p>
<p>对于这里的符号，n_c在学术文献中被称为通道(channel)或者深度(depth)，在视频中统一称为通道。</p>
<h1 id="单层卷积网络：One-layer-of-a-convolutional-network"><a href="#单层卷积网络：One-layer-of-a-convolutional-network" class="headerlink" title="单层卷积网络：One layer of a convolutional network"></a>单层卷积网络：One layer of a convolutional network</h1><p>本节讲的是如何构建卷积神经网络的卷积层。下面看一个例子。</p>
<p>这个例子与前面的使用多个过滤器例子相同。输入6x6x3的图像，再通过一个卷积核，我们将得到的输出加上参数b，再通过ReLu激活函数，同样得到4x4的矩阵。再将两个输出堆叠起来，从而得到4x4x2的输出，这便是卷积神经网络的一层。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-280ea14a37187b24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>将上述过程映射到标准神经网络中，可以解释为：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-bfc3ed93735c4ff3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>即将原始输入图像当做z[0]，也就是X，而卷积核为W[1]那么卷积的操作类似于”W[1]a[0]”，之后我们的卷积加偏置值也类似原有的”W[1]a[0]+b”，即Z，最后应用非线性函数得到4x4矩阵。通过这个过程，我们可以得到卷积神经网络中的一层。因为我们有2个过滤器，因此我们得到了4x4x2的输出；如果有10个过滤器，那么得到的就是4x4x10的输出。</p>
<p>接下来举例计算一层中的参数数目：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4fa87e9a9864a40a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>如图，对应的参数数目为10x(3x3x3+1)=280个参数。我们注意到，不论输入的图片有多大，无论是1000x1000，还是5000x5000，我们的参数仍然是280个，可以用这些过滤器来检测水平特征、垂直特征和其他特征。<strong>即使这些图片很大，参数却很少，这就是卷积神经网络的一个特征，叫做“避免过拟合(less prone to over fitting)”。</strong>现在我们知道了如何提取10个特征，将其应用到大图片上，而参数数量固定不变。</p>
<h2 id="Summary-of-notation"><a href="#Summary-of-notation" class="headerlink" title="Summary of notation"></a>Summary of notation</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-835c64616af3c9e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>注意，这个标记并没有在深度学习的文献中得到统一。上述标记的输入和输出对应一层卷积神经网络的输入输出，另外，输出的高和宽的计算方式也列在了右侧，即向下取整的那个式子。之后通过练习进行熟悉即可。</p>
<h1 id="简单卷积神经网络示例"><a href="#简单卷积神经网络示例" class="headerlink" title="简单卷积神经网络示例"></a>简单卷积神经网络示例</h1><p>假设我们有一张图片，想要做图片识别，比如分类问题。假设其大小为39x39x3，第一层的filter为3x3x3，对应的步长为1，padding为0，并且设filter有10个。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-99be17573b85d6a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>上述卷积神经网络一共通过了3个卷积层的处理。在最后得到的7x7x40的输出后，我们一共获得了194个特征，通过将这些特征平滑化，即映射为向量后，再通过logistic函数或者Softmax函数，得到最后的分类结果。</p>
<p>设计卷积神经网络时，确定上述的超参数是一件麻烦的事，比如决定过滤器的大小(filter size)、步幅(stride)、padding、使用多少个过滤器等等。另外在本节课要记住的是，随着神经网络计算深度不断加深，通常开始时的图像要大一些，高和宽随着深度加深而不断减小，而信道数量则在增加。</p>
<p>一个典型的卷积网络通常有三层，包括卷积层(Convolution)、池化层(Pooling)，以及全连接层(Fully connected)。虽然仅用卷积层也有可能构建出很好的神经网络，大部分的神经网络架构师依然会添加池化层和全连接层。幸运的是，池化层和全连接层要比卷积层更容易设计。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2271c5e0b5e7e42e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="池化层：Pooling-Layer"><a href="#池化层：Pooling-Layer" class="headerlink" title="池化层：Pooling Layer"></a>池化层：Pooling Layer</h1><p>除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。</p>
<h2 id="Max-Pooling-最大化池"><a href="#Max-Pooling-最大化池" class="headerlink" title="Max Pooling: 最大化池"></a>Max Pooling: 最大化池</h2><p>最大化池的示例如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-231d3cf598eae81f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>通过选取2x2区域内的最大值，映射到一个2x2的矩阵当中。而最大化池的超参数包括filter的大小，本文中为2，以及步幅stride的大小，本文为2。</p>
<p>对最大化池的直观解释：我们可以把右边的4x4区域看作是某些特征的集合，那么数字大意味着可能提取了一些特定特征。比如左上区域为9的整个特征可能是一个猫眼探测器。因此最大化池操作的功能就是只要在任何一个象限内提取到某个特征，它都会保留在最大化池的输出中。因此最大化运算的实际作用是如果在过滤器中提取到某个特征，那么保留其最大值；如果某个象限没有提取到特征，那么其中的最大值也还是会很小。而需要承认的是，人们使用最大化池的主要原因是此方法在很多实验中表现很好。另外最大化池有趣的一点是，它有一组超参数，但是并没有参数需要学习。一旦确定了f和s，那么就固定了。</p>
<p>另外，对于最大化池的输出，之前卷积输出的公式也适用于最大化池。以一个3x3的过滤器为例：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-21b37e65798b205e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>本例针对的是二维的输入，如果输入是三维的，那么就分信道执行，对每个信道执行相同的最大化操作。以上例为具体例子，如果我们的输入信道为n_c，那么输出为3x3xn_c。</p>
<h2 id="Average-Pooling-平均池化"><a href="#Average-Pooling-平均池化" class="headerlink" title="Average Pooling: 平均池化"></a>Average Pooling: 平均池化</h2><p>平均池化选取的不是区域的最大值，而是平均值，不过这种池化方法并不常用。当然，例外的是对于很深的深层神经网络来说，我们可以用平均池化来分解规模为7x7x1000的网络表示层，在整个空间求平均值，得到1x1x1000的输出。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4677b61194940de7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>在做pooling时，往往很少用到超参数padding。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-289b4ce9132362e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>另外，注意到pooling仅仅是提取静态属性，因此pooling中没有参数需要学习。而只需要设置超参数，这些超参数的值可以是人为设置的，也可以是通过交叉验证来设置。</p>
<h1 id="卷积神经网络示例"><a href="#卷积神经网络示例" class="headerlink" title="卷积神经网络示例"></a>卷积神经网络示例</h1><p>下面举一个手写数字识别的常见例子：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-74c0755a088a3f93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>可以看到，上述神经网络经历了以下阶段：CONV1-&gt;POOL1-&gt;CONV2-&gt;POOL2-&gt;FC3-&gt;FC4-&gt;Softmax。注意到，实际上计算层数时，将CONV和POOL算作一层，因为POOL中没有参数需要学习，因此不作为单独一层计算。另外可以发现一个规律，随着神经网络越深，发现n_H和n_W越来越小，而通道数量n_C则逐渐变大，这也是卷积网络常见的模式。另一个常用的卷积网络模式如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-01db157ba4575af2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>另外，可以注意到卷积网络有很多超参数。一个原则是：不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选择一个在别人任务中效果很好的架构，它也可能使用于你的任务。</p>
<p>接下来讲一讲激活值的维数、大小和参数的数量，可以手动计算一下。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-290ddcd54592a0bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>我们注意到以下几点：第一，输入层和池化层没有参数；第二，卷积层的参数相对较少，而更多的参数都存在于神经网络的全连接层；第三，发现随着神经网络的加深，激活值会逐渐减少。如果激活值下降太快，也会影响网络性能。许多卷积网络都具有这些属性和性质。</p>
<p>总结，一个卷积神经网络的基本模块包括卷积层、池化层和全连接层。许多计算机视觉研究在探索如何把这些基本模块整合起来，构建高效的神经网络。根据经验，找到整合基本构造模块最好的方法就是大量阅读别人的案例。</p>
<h1 id="为什么选择卷积"><a href="#为什么选择卷积" class="headerlink" title="为什么选择卷积"></a>为什么选择卷积</h1><h2 id="参数共享和稀疏连接"><a href="#参数共享和稀疏连接" class="headerlink" title="参数共享和稀疏连接"></a>参数共享和稀疏连接</h2><p>和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接。举个例子，假设对于下面的输入和输出：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-f80e3c253904cc19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>如果我们只使用全连接层，那么需要的参数大小为3072x4704，约为1400万个参数；而使用卷积，我们的参数大小只需要(5x5+1)x6=156。</p>
<p>卷积网络参数少有两个原因，一是参数共享，即我们可以在图片的不同区域中使用同样的参数，以便提取特征：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-af95572a5883cc17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>原因二是使用了稀疏连接。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-ecd1fa2389d4ad7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>给出一个具体的解释：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-7a65120579fbb54b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>从上图中，我们发现输出的最左上角上的0，只与36个输入特征的9个相连接，而与其他像素值无关。这就是稀疏连接的概念。</p>
<p>神经网络通过这两种机制来减少参数，使得我们可以用更小的训练集来训练，从而预防过拟合。另外，卷积神经网络善于捕捉平移不变(translation invariance)。通过观察发现，向右移动两个像素，图片中的猫依然清晰可见。这是因为神经网络的卷积结构使得即使移动几个像素，该图片仍然具有非常相似的特征，应该属于相同的输出标记。这就是卷积网络在计算机视觉任务中表现良好的原因。</p>
<h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-8c14793776391c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="本周作业"><a href="#本周作业" class="headerlink" title="本周作业"></a>本周作业</h1>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/19/deep-learningw9/" rel="next" title="第9周-机器学习ML策略(2)">
                <i class="fa fa-chevron-left"></i> 第9周-机器学习ML策略(2)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="DesmonDay" />
          <p class="site-author-name" itemprop="name">DesmonDay</p>
           
              <p class="site-description motion-element" itemprop="description">主攻方向：NLP</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">104</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DesmonDay" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#计算机视觉"><span class="nav-number">1.</span> <span class="nav-text">计算机视觉</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积运算：边缘检测示例"><span class="nav-number">2.</span> <span class="nav-text">卷积运算：边缘检测示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#更多边缘检测内容"><span class="nav-number">3.</span> <span class="nav-text">更多边缘检测内容</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Vertical-and-Horizontal-Edge-Detection"><span class="nav-number">3.1.</span> <span class="nav-text">Vertical and Horizontal Edge Detection</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Padding"><span class="nav-number">4.</span> <span class="nav-text">Padding</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Valid-and-Same-convolutions"><span class="nav-number">4.1.</span> <span class="nav-text">Valid and Same convolutions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积步长：Strided-convolutions"><span class="nav-number">5.</span> <span class="nav-text">卷积步长：Strided convolutions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-of-convolutions"><span class="nav-number">5.1.</span> <span class="nav-text">Summary of convolutions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Technical-note-on-cross-correlation-vs-convolution"><span class="nav-number">5.2.</span> <span class="nav-text">Technical note on cross-correlation vs. convolution</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三维卷积：Convolutions-volumes"><span class="nav-number">6.</span> <span class="nav-text">三维卷积：Convolutions volumes</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#单层卷积网络：One-layer-of-a-convolutional-network"><span class="nav-number">7.</span> <span class="nav-text">单层卷积网络：One layer of a convolutional network</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-of-notation"><span class="nav-number">7.1.</span> <span class="nav-text">Summary of notation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简单卷积神经网络示例"><span class="nav-number">8.</span> <span class="nav-text">简单卷积神经网络示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#池化层：Pooling-Layer"><span class="nav-number">9.</span> <span class="nav-text">池化层：Pooling Layer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Max-Pooling-最大化池"><span class="nav-number">9.1.</span> <span class="nav-text">Max Pooling: 最大化池</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Average-Pooling-平均池化"><span class="nav-number">9.2.</span> <span class="nav-text">Average Pooling: 平均池化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">9.3.</span> <span class="nav-text">Summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络示例"><span class="nav-number">10.</span> <span class="nav-text">卷积神经网络示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么选择卷积"><span class="nav-number">11.</span> <span class="nav-text">为什么选择卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#参数共享和稀疏连接"><span class="nav-number">11.1.</span> <span class="nav-text">参数共享和稀疏连接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#整合"><span class="nav-number">11.2.</span> <span class="nav-text">整合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#本周作业"><span class="nav-number">12.</span> <span class="nav-text">本周作业</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DesmonDay</span>
</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>


