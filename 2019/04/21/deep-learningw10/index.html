<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python," />





  <link rel="alternate" href="/atom.xml" title="DesmonDay's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="第10周-卷积神经网络">
<meta property="og:url" content="https://github.com/DesmonDay/2019/04/21/deep-learningw10/index.html">
<meta property="og:site_name" content="DesmonDay&#39;s Blog">
<meta property="og:description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2132ecef254524fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-24c5a8a203e46666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e5d257063b772320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4d3c64a43489e39c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-dc8899bc8d386eb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-b8a90a6aa25f7d62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-6bc7d0ef4bca22c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2fa4f586983b3583.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8f5daa4b3c5c6794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-51dbad653021f2cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-45c74100fa75f632.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-ebe1f304259697e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e7d237be92bbae53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8979cfce84796e30.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-0022fc160f42e86e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d8b67dbf0004c314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a17259e83c0465e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-84bdc3ef5cc59e88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8871e610b35fba21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-e9601faf7c8e6030.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d66f4cdd25a87444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-af5878b975293364.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-aff45991e5b60ae2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-7c18e494b51a7d40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-3abb380561e76211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4099faae498d0270.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a0ac14e4a54ed0e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-c27afbd37be9239b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-d0b784321e478e03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-280ea14a37187b24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-bfc3ed93735c4ff3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4fa87e9a9864a40a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-835c64616af3c9e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-99be17573b85d6a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2271c5e0b5e7e42e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-231d3cf598eae81f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-21b37e65798b205e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-4677b61194940de7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-289b4ce9132362e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-74c0755a088a3f93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-01db157ba4575af2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-290ddcd54592a0bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-f80e3c253904cc19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-af95572a5883cc17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-ecd1fa2389d4ad7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-7a65120579fbb54b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8c14793776391c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-7048e9ad0ba4f08f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-282eb6ec56a20d04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a6d4953e936eab7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-bf19d4ad2bac87e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-0c33896407f617d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-535f5da4758566ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-cd8e9f6b48eee975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-8e12bb6926cbe828.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-ac2760d7166ca719.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-2e088e8094180b32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-5d3173e6db1e5e5d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-29a302c85af0188d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-677db6a2620243b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-27ae8fc6c24d23b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-c4705e853cb55280.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-c77ae96f74c7b4d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2019-04-22T11:32:03.148Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第10周-卷积神经网络">
<meta name="twitter:description" content="接下来的四周为计算机视觉——卷积神经网络的内容。 计算机视觉常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。 在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/DesmonDay/2019/04/21/deep-learningw10/"/>





  <title>第10周-卷积神经网络 | DesmonDay's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DesmonDay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一只小辣鸡的自我拯救之路</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/DesmonDay/2019/04/21/deep-learningw10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DesmonDay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DesmonDay's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第10周-卷积神经网络</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-21T02:27:39+08:00">
                2019-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>接下来的四周为计算机视觉——卷积神经网络的内容。</p>
<h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><p>常见的计算机视觉问题包括图像分类、目标检测、神经网络实现的图片风格迁移等等。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-6da3b6dc31c4aac5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>在应用计算机视觉时，我们面临的一个挑战是数据的输入可能会非常大，以图片输入为例：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2132ecef254524fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以看到，如果我们采用的是64x64的图片，那么输入大小为12288，但如果是相对高清的图片，输入的大小可以达到3million。如果按照我们之前所讲全连接的神经网络来做，所需要的参数大小将会非常巨大，并且对内存的要求也很高。为了解决这种情况，我们使用的神经网络实际上为卷积神经网络。</p>
<h1 id="卷积运算：边缘检测示例"><a href="#卷积运算：边缘检测示例" class="headerlink" title="卷积运算：边缘检测示例"></a>卷积运算：边缘检测示例</h1><p>卷积运算是卷积神经网络的最基本的组成部分，我们使用边缘检测作为入门样例，了解卷积是如何进行计算的。</p>
<p>在进行图像识别的时候，我们会进行边缘检测，示例如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-24c5a8a203e46666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>如何在图像中检测这些边缘？下面举一个例子：我们给出一个6x6的灰度图像（因此只有一个颜色通道），也就是6x6x1的矩阵。为了检测图像中的垂直边缘，我们可以构造一个3x3的矩阵称为过滤器（又称卷积核，一般为3x3矩阵），再将图像矩阵与这个过滤矩阵做卷积运算。这个卷积运算的输出为4x4的矩阵。具体如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e5d257063b772320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>可以看到，我们按顺序移动蓝色方块，再将方块中的数字与卷积核进行计算，计算的方法即对应元素相乘后再相加，得到的结果再写入结果矩阵对应的位置中。因此，在左上角的蓝色方块中，我们的计算为3x1+1x1+2x1+0x0+5x0+7x0+1x)-1+8x(-1)+2x(-1)=-5，其他结果也一样通过这种方式获得。</p>
<p>卷积运算在python中为conv_forward，在tensorflow中为tf.nn.conv2d，在Keras框架中为Conv2D。几乎所有的编程框架都有提供一些函数来实现卷积运算。</p>
<p>用简单例子解释为何这种运算可以这样计算：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4d3c64a43489e39c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以发现，我们的图像中间有着一个明显的垂直直线，这条垂直线是从黑到白的过滤线。当用一个3x3过滤器进行卷积运算时，这个3x3过滤器可视为左边有明亮像素，中间有过渡(0)，右边有深色像素的图例。通过卷积运算后，我们的矩阵对应的图像，在中间有段明亮的区域，这可以对应检查到这个6x6图像中间的垂直边缘。（这里的维数有些不正确，即检测到的边缘过粗，这是因为在此例中的图片过小，当我们使用的是1000x1000的图像，会发现其能很好地检测图像中的垂直边缘。）通过这种卷积运算，我们可以发现图像中的垂直边缘。</p>
<h1 id="更多边缘检测内容"><a href="#更多边缘检测内容" class="headerlink" title="更多边缘检测内容"></a>更多边缘检测内容</h1><p>在本节中，我们会学习如何区分正边和负边（即由亮到暗与由暗到亮的区别），也就是边缘的过渡。我们也可以了解到其他类型的边缘检测以及如何实现这些算法。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8636110-dc8899bc8d386eb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>对比发现，上图为由亮到暗的过渡，而下图为由暗到亮的过渡。也就是说，中间的这个3x3卷积核能够帮助我们区分正边和负边。</p>
<h2 id="Vertical-and-Horizontal-Edge-Detection"><a href="#Vertical-and-Horizontal-Edge-Detection" class="headerlink" title="Vertical and Horizontal Edge Detection"></a>Vertical and Horizontal Edge Detection</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-b8a90a6aa25f7d62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>左边的卷积核针对垂直边缘，而右边的卷积核针对水平边缘。另外，我们可以通过上图的一个例子来验证水平边缘的检测正确性。在右边用橙色框出来的10，表明其左边为亮，右边为暗，对应着原图像的上面过渡部分，其他的值也可以这么对应分析。</p>
<p>总而言之，通过使用不同的滤波器，我们可以找出垂直的或者水平的边缘。但事实上，对于这个3x3的卷积核来说，我们只使用了其中一种数字组合。在计算机视觉的文献中，曾争论过怎样的数字组合猜是最好的。<br>1、Sobel过滤器，它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-6bc7d0ef4bca22c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>2、 Scharr过滤器，它有着和之前完全不同的特性，但实际上也是一钟垂直边缘检测，如果将其旋转90度，可以得到对应水平边缘检测。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2fa4f586983b3583.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>随着<strong>深度学习</strong>的发展，当我们真正想去检测出复杂图像的边缘，也许我们不需要使用研究者选择的数字，而是可以<strong>把这些数字当成参数</strong>，通过<strong>后向传播</strong>算法来得到对应值。相比垂直和水平边缘，这种方法也可以检验包括其他方向的边缘。将卷积核的所有数字设置为参数，通过数据反馈，让神经网络自动学习，我们会发现神经网络可以学习一些低级的特征，比如边缘的特征。构成这些计算的基础是卷积运算，因此使得反向传播算法能够让神经网络学习任何它所需要的3x3过滤器，并在整幅图片上应用它，输出它所检测的特征。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8f5daa4b3c5c6794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h1><p>在卷积神经网络中，一个基本的卷积操作就是padding。</p>
<p>在之前我们在做卷积运算示例中，我们的输出矩阵为4x4维度，这是因为我们使用的过滤器在原图片上只可能有4x4种可能的位置。对应的，如果我们有nxn的图像，而过滤器为fxf，那么输出结果的维度为(n-f+1)x(n-f+1)。这样做有两个缺点，一是每次做卷积操作，我们的图像会缩小，比如从6x6到4x4，如果再多几次卷积运算，那么我们的图像就会变得很小了；二是如果我们注意到角落边的像素，这个像素点只被一个输出使用，因为它只位于一个3x3区域的一角，但如果是在中间的像素点，那么会有很多3x3区域重叠。因此那些在角落或者边缘区域的像素点在输出中采用较少，意味着我们丢掉了图像边缘位置的许多信息。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-51dbad653021f2cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>为了解决这两个问题，一是输出缩小，二是图像边缘的大部分信息丢失，我们可以在卷积操作之前对图像进行填充。例如，对上述图像进行填充，由6x6变为了8x8，那么我们得到的输出和原始图像一样，都是6x6的图像。通常，我们用进行填充。如果p是填充的数量，那么在本例中，p=padding=1，那么输出就变为了(n+2p-f+1)x(n+2p-f+1)。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-45c74100fa75f632.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>通过填充，位于角落或图像边缘的信息发挥作用较小的缺点就被削弱了。如果我们想再增加像素填充，则可以得到p=2之类的填充后的图像，如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-ebe1f304259697e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Valid-and-Same-convolutions"><a href="#Valid-and-Same-convolutions" class="headerlink" title="Valid and Same convolutions"></a>Valid and Same convolutions</h2><p>至于填充多少像素，通常有两个选择，分别称为Valid卷积和Same卷积。Valid卷积意味着没有padding；而另一个Same卷积，这个方法意味着我们填充图像后，输出大小和原图像的大小是一样的，具体的计算过程见下图：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e7d237be92bbae53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>另外注意到，在计算机视觉的惯例中，<strong>f通常是奇数</strong>。原因一是奇数才可以保证对称的填充；二是计算机视觉通常需要一个中心位置，便于指出过滤器的位置。</p>
<h1 id="卷积步长：Strided-convolutions"><a href="#卷积步长：Strided-convolutions" class="headerlink" title="卷积步长：Strided convolutions"></a>卷积步长：Strided convolutions</h1><p>卷积步长是另一个构建卷积神经网络的基本操作，下面我们举例解释卷积步长的含义。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8979cfce84796e30.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在本例中，我们设置Stride=2。先计算第一个位置的输出：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-0022fc160f42e86e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>接下来，要计算下一个位置的输出。由于卷积步长为2，因此我们不像之前一样将3x3区域往右移动一位，而是移动两位进行计算，如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d8b67dbf0004c314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>继续右移两个单位：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a17259e83c0465e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当我们要移动到下一行的时候，我们的步长也是2，因此下一个位置如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-84bdc3ef5cc59e88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>等等等。最后得到的输出为：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8871e610b35fba21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>因此输入输出的维度由以下公式决定：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-e9601faf7c8e6030.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>注意到，如果商不是整数，在这种情况下我们可以向下取整。这个原则实现的方式是，你只在蓝框完全包括在图像或填充完的图像内部时，才对它进行运算。如果有的蓝框移动到了图像外部，那么我们不对其进行运算。也就是说，我们的3x3过滤器必须处于图像中或者填充之后的图像区域内，因此要向下取整。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d66f4cdd25a87444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Summary-of-convolutions"><a href="#Summary-of-convolutions" class="headerlink" title="Summary of convolutions"></a>Summary of convolutions</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-af5878b975293364.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Technical-note-on-cross-correlation-vs-convolution"><a href="#Technical-note-on-cross-correlation-vs-convolution" class="headerlink" title="Technical note on cross-correlation vs. convolution"></a>Technical note on cross-correlation vs. convolution</h2><p>这里讲解一个关于互相关和卷积的技术性建议，这不会影响到我们构建卷积神经网络的方式。如果我们看的是一本典型的数学教科书，那么卷积的定义是做元素乘积求和，实际上还有一个步骤是我们首先要做的，也就是在把这个6x6矩阵和3x3的过滤器卷积前，首先将3x3的过滤器沿水平和垂直轴翻转（先顺时针旋转90度，再水平翻转），用得到的矩阵来做元素相乘求和的操作。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-aff45991e5b60ae2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>从技术上讲，这个操作被称为互相关。在深度学习领域中，有很多人把它叫做卷积运算，但我们通常不需要用到翻转的步骤。事实证明在信号处理货某些数学分支中，卷积的定义包含翻转，使得卷积运算符拥有(A*B)*C=A*(B*C)的结合律性质。这对于一些信号处理应用来说很好，但对深度神经网络而言并不重要，因此我们忽略了这个双重镜像操作，从而简化代码。</p>
<p>综上所述，我们学习了如何进行卷积、如何使用填充、如何在卷积中选择步长，但我们目前为止使用的是关于矩阵的卷积。接下来会讲解如何对立体进行卷积。</p>
<h1 id="三维卷积：Convolutions-volumes"><a href="#三维卷积：Convolutions-volumes" class="headerlink" title="三维卷积：Convolutions volumes"></a>三维卷积：Convolutions volumes</h1><p>本节讲解如何在三维立体上进行卷积运算。假设我们想要检测RGB彩色图像的特征，即具有三个颜色通道。因此其维度为6x6x3，因此过滤器也需要是3x3x3的维度：（高、宽、通道个数）<br><img src="https://upload-images.jianshu.io/upload_images/8636110-7c18e494b51a7d40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>接下来研究背后的细节。其实实际的计算过程与二维的也很类似，我们将过滤器当做一个正方体，放置到原三维图像上，然后将这27个数字对应相乘和相加，填入输出的对应位置即可：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-3abb380561e76211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>再将立方体往右移一个单位，得到下一位，等等等，直到到达最后一位。</p>
<p>那么这个过滤器的作用是什么？举个例子，这个过滤器是3x3x3的，如果我们想检测图像红色通道的垂直边缘，而不关心其他通道，那么可以将三个过滤器分别设置如下后，再进行堆叠：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4099faae498d0270.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当然，如果我们想检测所有通道的垂直边缘，则可以使用这样的过滤器。因此，参数的不同选择，可以得到不同的过滤器。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a0ac14e4a54ed0e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>按照计算机视觉的惯例，当你的输入有特定的高宽和通道数时，我们的过滤器可以有不同的高，不同的宽，但是通道数必须相同。现在，我们了解了如何对立方体卷积，那么，如果我们想要同时检测垂直边缘和水平边缘，以及其他方向的边缘应该怎么做？换句话说，想同时使用多个过滤器，应该怎么办？</p>
<p>假设我们同时使用水平过滤器和垂直过滤器，过程如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-c27afbd37be9239b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>简单来说，我们得到的输出也成为了一个三维立体，这样就是同时两用了多个过滤器。</p>
<p>下面对维度进行总结：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-d0b784321e478e03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>即输入的彩色图像为nxnxn_c，过滤器为fxfxn_c，这里n_c为通道数目，那么输出的维度为(n-f+1)x(n-f+1)xn_c’，这里n_c’指所应用的过滤器数目，即输出的通道数等于我们要检测的特征数。比如对前面的同时使用水平过滤器和垂直过滤器来说，n_c’=2。另外，这个式子默认我们没有使用padding。</p>
<p>对于这里的符号，n_c在学术文献中被称为通道(channel)或者深度(depth)，在视频中统一称为通道。</p>
<h1 id="单层卷积网络：One-layer-of-a-convolutional-network"><a href="#单层卷积网络：One-layer-of-a-convolutional-network" class="headerlink" title="单层卷积网络：One layer of a convolutional network"></a>单层卷积网络：One layer of a convolutional network</h1><p>本节讲的是如何构建卷积神经网络的卷积层。下面看一个例子。</p>
<p>这个例子与前面的使用多个过滤器例子相同。输入6x6x3的图像，再通过一个卷积核，我们将得到的输出加上参数b，再通过ReLu激活函数，同样得到4x4的矩阵。再将两个输出堆叠起来，从而得到4x4x2的输出，这便是卷积神经网络的一层。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-280ea14a37187b24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>将上述过程映射到标准神经网络中，可以解释为：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-bfc3ed93735c4ff3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>即将原始输入图像当做z[0]，也就是X，而卷积核为W[1]那么卷积的操作类似于”W[1]a[0]”，之后我们的卷积加偏置值也类似原有的”W[1]a[0]+b”，即Z，最后应用非线性函数得到4x4矩阵。通过这个过程，我们可以得到卷积神经网络中的一层。因为我们有2个过滤器，因此我们得到了4x4x2的输出；如果有10个过滤器，那么得到的就是4x4x10的输出。</p>
<p>接下来举例计算一层中的参数数目：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4fa87e9a9864a40a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>如图，对应的参数数目为10x(3x3x3+1)=280个参数。我们注意到，不论输入的图片有多大，无论是1000x1000，还是5000x5000，我们的参数仍然是280个，可以用这些过滤器来检测水平特征、垂直特征和其他特征。<strong>即使这些图片很大，参数却很少，这就是卷积神经网络的一个特征，叫做“避免过拟合(less prone to over fitting)”。</strong>现在我们知道了如何提取10个特征，将其应用到大图片上，而参数数量固定不变。</p>
<h2 id="Summary-of-notation"><a href="#Summary-of-notation" class="headerlink" title="Summary of notation"></a>Summary of notation</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-835c64616af3c9e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>注意，这个标记并没有在深度学习的文献中得到统一。上述标记的输入和输出对应一层卷积神经网络的输入输出，另外，输出的高和宽的计算方式也列在了右侧，即向下取整的那个式子。之后通过练习进行熟悉即可。</p>
<h1 id="简单卷积神经网络示例"><a href="#简单卷积神经网络示例" class="headerlink" title="简单卷积神经网络示例"></a>简单卷积神经网络示例</h1><p>假设我们有一张图片，想要做图片识别，比如分类问题。假设其大小为39x39x3，第一层的filter为3x3x3，对应的步长为1，padding为0，并且设filter有10个。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-99be17573b85d6a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>上述卷积神经网络一共通过了3个卷积层的处理。在最后得到的7x7x40的输出后，我们一共获得了194个特征，通过将这些特征平滑化，即映射为向量后，再通过logistic函数或者Softmax函数，得到最后的分类结果。</p>
<p>设计卷积神经网络时，确定上述的超参数是一件麻烦的事，比如决定过滤器的大小(filter size)、步幅(stride)、padding、使用多少个过滤器等等。另外在本节课要记住的是，随着神经网络计算深度不断加深，通常开始时的图像要大一些，高和宽随着深度加深而不断减小，而信道数量则在增加。</p>
<p>一个典型的卷积网络通常有三层，包括卷积层(Convolution)、池化层(Pooling)，以及全连接层(Fully connected)。虽然仅用卷积层也有可能构建出很好的神经网络，大部分的神经网络架构师依然会添加池化层和全连接层。幸运的是，池化层和全连接层要比卷积层更容易设计。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2271c5e0b5e7e42e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="池化层：Pooling-Layer"><a href="#池化层：Pooling-Layer" class="headerlink" title="池化层：Pooling Layer"></a>池化层：Pooling Layer</h1><p>除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。</p>
<h2 id="Max-Pooling-最大化池"><a href="#Max-Pooling-最大化池" class="headerlink" title="Max Pooling: 最大化池"></a>Max Pooling: 最大化池</h2><p>最大化池的示例如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-231d3cf598eae81f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>通过选取2x2区域内的最大值，映射到一个2x2的矩阵当中。而最大化池的超参数包括filter的大小，本文中为2，以及步幅stride的大小，本文为2。</p>
<p>对最大化池的直观解释：我们可以把右边的4x4区域看作是某些特征的集合，那么数字大意味着可能提取了一些特定特征。比如左上区域为9的整个特征可能是一个猫眼探测器。因此最大化池操作的功能就是只要在任何一个象限内提取到某个特征，它都会保留在最大化池的输出中。因此最大化运算的实际作用是如果在过滤器中提取到某个特征，那么保留其最大值；如果某个象限没有提取到特征，那么其中的最大值也还是会很小。而需要承认的是，人们使用最大化池的主要原因是此方法在很多实验中表现很好。另外最大化池有趣的一点是，它有一组超参数，但是并没有参数需要学习。一旦确定了f和s，那么就固定了。</p>
<p>另外，对于最大化池的输出，之前卷积输出的公式也适用于最大化池。以一个3x3的过滤器为例：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-21b37e65798b205e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>本例针对的是二维的输入，如果输入是三维的，那么就分信道执行，对每个信道执行相同的最大化操作。以上例为具体例子，如果我们的输入信道为n_c，那么输出为3x3xn_c。</p>
<h2 id="Average-Pooling-平均池化"><a href="#Average-Pooling-平均池化" class="headerlink" title="Average Pooling: 平均池化"></a>Average Pooling: 平均池化</h2><p>平均池化选取的不是区域的最大值，而是平均值，不过这种池化方法并不常用。当然，例外的是对于很深的深层神经网络来说，我们可以用平均池化来分解规模为7x7x1000的网络表示层，在整个空间求平均值，得到1x1x1000的输出。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-4677b61194940de7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>在做pooling时，往往很少用到超参数padding。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-289b4ce9132362e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>另外，注意到pooling仅仅是提取静态属性，因此pooling中没有参数需要学习。而只需要设置超参数，这些超参数的值可以是人为设置的，也可以是通过交叉验证来设置。</p>
<h1 id="卷积神经网络示例"><a href="#卷积神经网络示例" class="headerlink" title="卷积神经网络示例"></a>卷积神经网络示例</h1><p>下面举一个手写数字识别的常见例子：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-74c0755a088a3f93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>可以看到，上述神经网络经历了以下阶段：CONV1-&gt;POOL1-&gt;CONV2-&gt;POOL2-&gt;FC3-&gt;FC4-&gt;Softmax。注意到，实际上计算层数时，将CONV和POOL算作一层，因为POOL中没有参数需要学习，因此不作为单独一层计算。另外可以发现一个规律，随着神经网络越深，发现n_H和n_W越来越小，而通道数量n_C则逐渐变大，这也是卷积网络常见的模式。另一个常用的卷积网络模式如下：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-01db157ba4575af2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>另外，可以注意到卷积网络有很多超参数。一个原则是：不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选择一个在别人任务中效果很好的架构，它也可能使用于你的任务。</p>
<p>接下来讲一讲激活值的维数、大小和参数的数量，可以手动计算一下。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-290ddcd54592a0bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>我们注意到以下几点：第一，输入层和池化层没有参数；第二，卷积层的参数相对较少，而更多的参数都存在于神经网络的全连接层；第三，发现随着神经网络的加深，激活值会逐渐减少。如果激活值下降太快，也会影响网络性能。许多卷积网络都具有这些属性和性质。</p>
<p>总结，一个卷积神经网络的基本模块包括卷积层、池化层和全连接层。许多计算机视觉研究在探索如何把这些基本模块整合起来，构建高效的神经网络。根据经验，找到整合基本构造模块最好的方法就是大量阅读别人的案例。</p>
<h1 id="为什么选择卷积"><a href="#为什么选择卷积" class="headerlink" title="为什么选择卷积"></a>为什么选择卷积</h1><h2 id="参数共享和稀疏连接"><a href="#参数共享和稀疏连接" class="headerlink" title="参数共享和稀疏连接"></a>参数共享和稀疏连接</h2><p>和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接。举个例子，假设对于下面的输入和输出：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-f80e3c253904cc19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>如果我们只使用全连接层，那么需要的参数大小为3072x4704，约为1400万个参数；而使用卷积，我们的参数大小只需要(5x5+1)x6=156。</p>
<p>卷积网络参数少有两个原因，一是参数共享，即我们可以在图片的不同区域中使用同样的参数，以便提取特征：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-af95572a5883cc17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>原因二是使用了稀疏连接。<br><img src="https://upload-images.jianshu.io/upload_images/8636110-ecd1fa2389d4ad7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>给出一个具体的解释：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-7a65120579fbb54b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>从上图中，我们发现输出的最左上角上的0，只与36个输入特征的9个相连接，而与其他像素值无关。这就是稀疏连接的概念。</p>
<p>神经网络通过这两种机制来减少参数，使得我们可以用更小的训练集来训练，从而预防过拟合。另外，卷积神经网络善于捕捉平移不变(translation invariance)。通过观察发现，向右移动两个像素，图片中的猫依然清晰可见。这是因为神经网络的卷积结构使得即使移动几个像素，该图片仍然具有非常相似的特征，应该属于相同的输出标记。这就是卷积网络在计算机视觉任务中表现良好的原因。</p>
<h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><p><img src="https://upload-images.jianshu.io/upload_images/8636110-8c14793776391c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h1 id="本周作业"><a href="#本周作业" class="headerlink" title="本周作业"></a>本周作业</h1><h2 id="Convolutional-Neural-Networks-Step-by-Step"><a href="#Convolutional-Neural-Networks-Step-by-Step" class="headerlink" title="Convolutional Neural Networks: Step by Step"></a>Convolutional Neural Networks: Step by Step</h2><h3 id="1-Packages"><a href="#1-Packages" class="headerlink" title="1- Packages"></a>1- Packages</h3><p>导入包：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="2-Outline-of-the-Assignment"><a href="#2-Outline-of-the-Assignment" class="headerlink" title="2- Outline of the Assignment"></a>2- Outline of the Assignment</h3><p>You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:</p>
<ul>
<li>Convolution functions, including:<ul>
<li>Zero Padding</li>
<li>Convolve window</li>
<li>Convolution forward</li>
<li>Convolution backward </li>
</ul>
</li>
<li>Pooling functions, including:<ul>
<li>Pooling forward</li>
<li>Create mask </li>
<li>Distribute value</li>
<li>Pooling backward </li>
</ul>
</li>
</ul>
<p>This notebook will ask you to implement these functions from scratch in numpy. In the next notebook, you will use the TensorFlow equivalents of these functions to build the following model:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-7048e9ad0ba4f08f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>Note that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation.</p>
<h3 id="3-Convolutional-Neural-Networks"><a href="#3-Convolutional-Neural-Networks" class="headerlink" title="3- Convolutional Neural Networks"></a>3- Convolutional Neural Networks</h3><p>Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below.<br><img src="https://upload-images.jianshu.io/upload_images/8636110-282eb6ec56a20d04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself.</p>
<h4 id="3-1-Zero-Padding"><a href="#3-1-Zero-Padding" class="headerlink" title="3.1- Zero-Padding"></a>3.1- Zero-Padding</h4><p>Zero-padding adds zeros around the border of an image:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a6d4953e936eab7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><strong>The main benefits of padding are the following:</strong></p>
<ul>
<li>It allows you to use a CONV layer without necessarily shrinking(收缩) the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the “same” convolution, in which the height/width is exactly preserved after one layer.</li>
<li>It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.</li>
</ul>
<p><strong>Exercise</strong>: Implement the following function, which pads all the images of a batch of examples X with zeros. <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html" target="_blank" rel="noopener">Use np.pad</a>. Note if you want to pad the array “a” of shape (5,5,5,5,5) with <code>pad = 1</code> for the 2nd dimension, <code>pad = 3</code> for the 4th dimension and <code>pad = 0</code> for the rest, you would do:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = np.pad(a, ((<span class="number">0</span>,<span class="number">0</span>), (<span class="number">1</span>,<span class="number">1</span>), (<span class="number">0</span>,<span class="number">0</span>), (<span class="number">3</span>,<span class="number">3</span>), (<span class="number">0</span>,<span class="number">0</span>)), <span class="string">'constant'</span>, constant_values = (..,..))</span><br></pre></td></tr></table></figure></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_pad</span><span class="params">(X, pad)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, </span></span><br><span class="line"><span class="string">    as illustrated in Figure 1.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images</span></span><br><span class="line"><span class="string">    pad -- integer, amount of padding around each image on vertical and horizontal dimensions</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    X_pad = np.pad(X, ((<span class="number">0</span>,<span class="number">0</span>),(pad,pad),(pad,pad),(<span class="number">0</span>,<span class="number">0</span>)), <span class="string">'constant'</span>, constant_values=(<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X_pad</span><br></pre></td></tr></table></figure>
<p>示例输出：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-bf19d4ad2bac87e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="3-2-Single-step-of-convolution"><a href="#3-2-Single-step-of-convolution" class="headerlink" title="3.2- Single step of convolution"></a>3.2- Single step of convolution</h4><p>In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which:</p>
<ul>
<li>Takes an input volume</li>
<li>Applies a filter at every position of the input</li>
<li>Outputs another volume(usually of different size)</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/8636110-0c33896407f617d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output.</p>
<p>Later in this notebook, you’ll apply this function to multiple positions of the input to implement the full convolutional operation.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_single_step</span><span class="params">(a_slice_prev, W, b)</span>:</span> <span class="comment">#注意这里的a_slice_prev，需要和W对应维度</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation </span></span><br><span class="line"><span class="string">    of the previous layer.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)</span></span><br><span class="line"><span class="string">    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)</span></span><br><span class="line"><span class="string">    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    <span class="comment"># Element-wise product between a_slice and W. Add bias.</span></span><br><span class="line">    s = a_slice_prev * W + b</span><br><span class="line">    <span class="comment"># Sum over all entries of the volume s</span></span><br><span class="line">    Z = np.sum(s)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z</span><br></pre></td></tr></table></figure>
<h4 id="3-3-Convolutional-Neural-Networks-Forward-pass"><a href="#3-3-Convolutional-Neural-Networks-Forward-pass" class="headerlink" title="3.3- Convolutional Neural Networks - Forward pass"></a>3.3- Convolutional Neural Networks - Forward pass</h4><p>In the forward pass, you will take many filters and convolve them on the input. Each ‘convolution’ gives you a 2D matrix output. You will then stack these outputs to get a 3D volume.</p>
<p><strong>Exercise</strong>: Implement the function below to convolve the filters W on an input activation A_prev. This function takes as input A_prev, the activations output by the previous layer (for a batch of m inputs), F filters/weights denoted by W, and a bias vector denoted by b, where each filter has its own (single) bias. Finally you also have access to the hyperparameters dictionary which contains the stride and the padding.</p>
<p><strong>Hint</strong>:</p>
<ol>
<li>To select a 2x2 slice at the upper left corner of a matrix “a_prev” (shape (5,5,3)), you would do:<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a_slice_prev = a_prev[<span class="number">0</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">2</span>,:]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>This will be useful when you will define a_slice_prev below, using the start/end indexes you will define.</p>
<ol>
<li>To define a_slice you will need to first define its corners vert_start, vert_end, horiz_start and horiz_end. This figure may be helpful for you to find how each of the corner can be defined using h, w, f and s in the code below.<br><img src="https://upload-images.jianshu.io/upload_images/8636110-535f5da4758566ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></li>
</ol>
<p><strong>Reminder</strong>: The formulas relating the output shape of the convolution to the input shape is:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-cd8e9f6b48eee975.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>For this exercise, we won’t worry about vectorization, and will just implement everything with for-loops.</p>
<p>对于此部分，需要注意的是vert_start/vert_end/horiz_start/horiz_end的计算方式。这里我一开始是没有考虑到stride的，大错特错！<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_forward</span><span class="params">(A_prev, W, b, hyperparameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation for a convolution function</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)</span></span><br><span class="line"><span class="string">    b -- Biases, numpy array of shape (1, 1, 1, n_C)</span></span><br><span class="line"><span class="string">    hparameters -- python dictionary containing "stride" and "pad"</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    cache -- cache of values needed for the conv_backward() function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape (≈1 line)  </span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape (≈1 line)</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">"stride"</span>]</span><br><span class="line">    pad = hparameters[<span class="string">"pad"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)</span></span><br><span class="line">    n_H = int((n_H_prev-f+<span class="number">2</span>*pad)/stride) + <span class="number">1</span></span><br><span class="line">    n_W = int((n_W_prev-f+<span class="number">2</span>*pad)/stride) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize the output volume Z with zeros. (≈1 line)</span></span><br><span class="line">    Z = np.zeros((m, n_H, n_W, n_C))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create A_prev_pad by padding A_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        a_prev_pad = A_prev_pad[i]</span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):</span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):</span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines) 这里要注意！</span></span><br><span class="line">                    vert_start = h * stride</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = w * stride</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)</span></span><br><span class="line">                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)</span></span><br><span class="line">                    Z[i,h,w,c] = conv_single_step(a_slice_prev, W[:,:,:,c], b[:,:,:,c])</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(Z.shape == (m, n_H, n_W, n_C))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save information in "cache" for the backprop</span></span><br><span class="line">    cache = (A_prev, W, b, hparameters)</span><br></pre></td></tr></table></figure></p>
<p>Finally, CONV layer should also contain an activation, in which case we would add the following line of code:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convolve the window to get back one output neuron</span></span><br><span class="line">Z[i, h, w, c] = ...</span><br><span class="line"><span class="comment"># Apply activation</span></span><br><span class="line">A[i, h, w, c] = activation(Z[i, h, w, c])</span><br></pre></td></tr></table></figure></p>
<h3 id="4-Pooling-layer"><a href="#4-Pooling-layer" class="headerlink" title="4- Pooling layer"></a>4- Pooling layer</h3><p>The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are:</p>
<ul>
<li>Max-pooling layer: slides an (f,f) window over the input and stores the max value of the window in the output.</li>
<li>Average-pooling layer: slides an (f,f) window over the input and stores the average value of the window in the output.<br><img src="https://upload-images.jianshu.io/upload_images/8636110-8e12bb6926cbe828.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></li>
</ul>
<p>These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size f. This specifies the height and width of the fxf window you would compute a max or average over.</p>
<h4 id="4-1-Forward-Pooling"><a href="#4-1-Forward-Pooling" class="headerlink" title="4.1- Forward Pooling"></a>4.1- Forward Pooling</h4><p>Now, you are going to implement MAX-POOL and AVG-POOL, in the same function.<br><strong>Reminder</strong>: As there’s no padding, the formulas binding the output shape of the pooling to the input shape is:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-ac2760d7166ca719.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_forward</span><span class="params">(A_prev, hparameters, mode=<span class="string">"max"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward pass of the pooling layer</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    hparameters -- python dictionary containing "f" and "stride"</span></span><br><span class="line"><span class="string">    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve dimensions from the input shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters"</span></span><br><span class="line">    f = hparameters[<span class="string">"f"</span>]</span><br><span class="line">    stride = hparameters[<span class="string">"stride"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the dimensions of the output</span></span><br><span class="line">    n_H = int(<span class="number">1</span> + (n_H_prev - f) / stride)</span><br><span class="line">    n_W = int(<span class="number">1</span> + (n_W_prev - f) / stride)</span><br><span class="line">    n_C = n_C_prev</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize output matrix A</span></span><br><span class="line">    A = np.zeros((m, n_H, n_W, n_C))      </span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):</span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):</span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = h * stride</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = w * stride</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)</span></span><br><span class="line">                    a_prev_slice = A_prev[i,vert_start:vert_end,horiz_start:horiz_end, c]</span><br><span class="line">                    <span class="comment"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.max(a_prev_slice)</span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.mean(a_prev_slice)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Store the input and hparameters in "cache" for pool_backward()</span></span><br><span class="line">    cache = (A_prev, hparameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(A.shape == (m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br></pre></td></tr></table></figure></p>
<h3 id="5-Backpropagation-in-convolutional-neural-networks"><a href="#5-Backpropagation-in-convolutional-neural-networks" class="headerlink" title="5- Backpropagation in convolutional neural networks"></a>5- Backpropagation in convolutional neural networks</h3><p>In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers don’t need to bother with the details of the backward pass. The backward pass for convolutional networks is complicated. If you wish however, you can work through this optional portion of the notebook to get a sense of what backprop in a convolutional network looks like.</p>
<p>When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in convolutional neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are not trivial and we did not derive them in lecture, but we briefly presented them below.</p>
<h4 id="5-1-Convolutional-layer-backward-pass"><a href="#5-1-Convolutional-layer-backward-pass" class="headerlink" title="5.1- Convolutional layer backward pass"></a>5.1- Convolutional layer backward pass</h4><p>Let’s start by implementing the backward pass for a CONV layer.</p>
<h4 id="5-1-1-Computing-dA"><a href="#5-1-1-Computing-dA" class="headerlink" title="5.1.1- Computing dA:"></a>5.1.1- Computing dA:</h4><p>This is the formula for computing dA with respect to the cost for a certain filter  Wc and a given training example:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-2e088e8094180b32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>Where Wc is a filter and dZ_hw is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). Note that at each time, we multiply the the same filter  WcWc  by a different dZ when updating dA. We do so mainly because when computing the forward propagation, each filter is dotted and summed by a different a_slice. Therefore when computing the backprop for dA, we are just adding the gradients of all the a_slices.</p>
<p>In code, inside the appropriate for-loops, this formula translates into:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure></p>
<h4 id="5-1-2-Computing-dW"><a href="#5-1-2-Computing-dW" class="headerlink" title="5.1.2- Computing dW:"></a>5.1.2- Computing dW:</h4><p>This is the formula for computing dWc( dWc is the derivative of one filter) with respect to the loss:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-5d3173e6db1e5e5d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>Where a_slice corresponds to the slice which was used to generate the acitivation  Z_ij. Hence, this ends up giving us the gradient for W with respect to that slice. Since it is the same W, we will just add up all such gradients to get dW.</p>
<p>In code, inside the appropriate for-loops, this formula translates into:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure></p>
<h4 id="5-1-3-Computing-db"><a href="#5-1-3-Computing-db" class="headerlink" title="5.1.3- Computing db:"></a>5.1.3- Computing db:</h4><p>This is the formula for computing db with respect to the cost for a certain filter W_c:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-29a302c85af0188d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>As you have previously seen in basic neural networks, db is computed by summing $dZ$. In this case, you are just summing over all the gradients of the conv output (Z) with respect to the cost. </p>
<p>In code, inside the appropriate for-loops, this formula translates into:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db[:,:,:,c] += dZ[i, h, w, c]</span><br></pre></td></tr></table></figure></p>
<p><strong>Exercise</strong>: Implement the <code>conv_backward</code> function below. You should sum over all the training examples, filters, heights, and widths. You should then compute the derivatives using formulas 1, 2 and 3 above.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_backward</span><span class="params">(dZ, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation for a convolution function</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    cache -- cache of values needed for the conv_backward(), output of conv_forward()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),</span></span><br><span class="line"><span class="string">               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    dW -- gradient of the cost with respect to the weights of the conv layer (W)</span></span><br><span class="line"><span class="string">          numpy array of shape (f, f, n_C_prev, n_C)</span></span><br><span class="line"><span class="string">    db -- gradient of the cost with respect to the biases of the conv layer (b)</span></span><br><span class="line"><span class="string">          numpy array of shape (1, 1, 1, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (A_prev, W, b, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters"</span></span><br><span class="line">    stride = hparameters[<span class="string">"stride"</span>]</span><br><span class="line">    pad = hparameters[<span class="string">"pad"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from dZ's shape</span></span><br><span class="line">    (m, n_H, n_W, n_C) = dZ.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev, dW, db with the correct shapes</span></span><br><span class="line">    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                         </span><br><span class="line">    dW = np.zeros((f, f, n_C_prev, n_C))</span><br><span class="line">    db = np.zeros((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,n_C))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pad A_prev and dA_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line">    dA_prev_pad = zero_pad(dA_prev, pad)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select ith training example from A_prev_pad and dA_prev_pad</span></span><br><span class="line">        a_prev_pad = A_prev_pad[i,:,:,:]</span><br><span class="line">        da_prev_pad = dA_prev_pad[i,:,:,:]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop over vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop over horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels of the output volume</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice"</span></span><br><span class="line">                    vert_start = h * stride</span><br><span class="line">                    vert_end = vert_start + f </span><br><span class="line">                    horiz_start = w * stride</span><br><span class="line">                    horiz_end = horiz_start + f </span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Use the corners to define the slice from a_prev_pad</span></span><br><span class="line">                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Update gradients for the window and the filter's parameters using the code formulas given above</span></span><br><span class="line">                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]</span><br><span class="line">                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br><span class="line">                    db[:,:,:,c] += dZ[i, h, w, c]</span><br><span class="line">                    </span><br><span class="line">        <span class="comment"># Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])</span></span><br><span class="line">        dA_prev_pad[i] = da_prev_pad[pad:-pad,pad:-pad,:]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure></p>
<h3 id="5-2-Pooling-layer-backward-pass"><a href="#5-2-Pooling-layer-backward-pass" class="headerlink" title="5.2- Pooling layer - backward pass"></a>5.2- Pooling layer - backward pass</h3><p>Next, let’s implement the backward pass for the pooling layer, starting with the MAX-POOL layer. Even though a pooling layer has no parameters for backprop to update, you still need to backpropagation the gradient through the pooling layer in order to compute gradients for layers that came before the pooling layer.</p>
<h4 id="5-2-1-Max-pooling-backward-pass"><a href="#5-2-1-Max-pooling-backward-pass" class="headerlink" title="5.2.1- Max pooling - backward pass"></a>5.2.1- Max pooling - backward pass</h4><p>Before jumping into the backpropagation of the pooling layer, you are going to build a helper function called create_mask_from_window() which does the following:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-677db6a2620243b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>As you can see, this function creates a “mask” matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You’ll see later that the backward pass for average pooling will be similar to this but using a different mask.</p>
<p><strong>Exercise</strong>: Implement <code>create_mask_from_window()</code>. This function will be helpful for pooling backward.<br>Hints:</p>
<ul>
<li><a href="">np.max()</a> may be helpful. It computes the maximum of an array.</li>
<li><p>If you have a matrix X and a scalar x: <code>A = (X == x)</code> will return a matrix A of the same size as X such that:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A[i,j] = True if X[i,j] = x</span><br><span class="line">A[i,j] = False if X[i,j] != x</span><br></pre></td></tr></table></figure>
</li>
<li><p>Here, you don’t need to consider cases where there are several maxima in a matrix.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_mask_from_window</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a mask from an input matrix x, to identify the max entry of x.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- Array of shape (f, f)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    mask = (x == np.max(x))</span><br><span class="line">    <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Why do we keep track of the position of the max? It’s because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will “propagate” the gradient back to this particular input value that had influenced the cost.</p>
<h4 id="5-2-2-Average-pooling-backward-pass"><a href="#5-2-2-Average-pooling-backward-pass" class="headerlink" title="5.2.2- Average pooling - backward pass"></a>5.2.2- Average pooling - backward pass</h4><p>In max pooling, for each input window, all the “influence” on the output came from a single input value—the max. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.</p>
<p>For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you’ll use for the backward pass will look like:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-27ae8fc6c24d23b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>This implies that each position in the dZ matrix contributes equally to output because in the forward pass, we took an average.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute_value</span><span class="params">(dz, shape)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Distributes the input value in the matrix of dimension shape</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dz -- input scalar</span></span><br><span class="line"><span class="string">    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    a -- Array of size (n_H, n_W) for which we distributed the value of dz</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from shape (≈1 line)</span></span><br><span class="line">    (n_H, n_W) = shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the value to distribute on the matrix (≈1 line)</span></span><br><span class="line">    average = dz / (n_H * n_W)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a matrix where every entry is the "average" value (≈1 line)</span></span><br><span class="line">    a = np.full(shape, average)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure>
<p>np.full(shape, value)函数可以将array的每个值初始化为value，且array的维度设置为shape。</p>
<h4 id="5-2-3-Putting-it-together-Pooling-backward"><a href="#5-2-3-Putting-it-together-Pooling-backward" class="headerlink" title="5.2.3- Putting it together: Pooling backward"></a>5.2.3- Putting it together: Pooling backward</h4><p>You now have everything you need to compute backward propagation on a pooling layer.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_backward</span><span class="params">(dA, cache, mode = <span class="string">"max"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the backward pass of the pooling layer</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A</span></span><br><span class="line"><span class="string">    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters </span></span><br><span class="line"><span class="string">    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from cache (≈1 line)</span></span><br><span class="line">    (A_prev, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    f = hparameters[<span class="string">'f'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)</span></span><br><span class="line">    m, n_H_prev, n_W_prev, n_C_prev = np.shape(A_prev)</span><br><span class="line">    m, n_H, n_W, n_C = np.shape(dA)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev with zeros (≈1 line)</span></span><br><span class="line">    dA_prev = np.zeros(np.shape(A_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select training example from A_prev (≈1 line)</span></span><br><span class="line">        a_prev = A_prev[i]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop on the vertical axis</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop on the horizontal axis</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels (depth)</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = h * stride</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = w * stride</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Compute the backward propagation in both modes.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Use the corners and "c" to define the current slice from a_prev (≈1 line)</span></span><br><span class="line">                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Create the mask from a_prev_slice (≈1 line)</span></span><br><span class="line">                        mask = create_mask_from_window(a_prev_slice)</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask, dA[i, h, w, c])</span><br><span class="line">                        </span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Get the value a from dA (≈1 line)</span></span><br><span class="line">                        da = dA[i, h, w, c]</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Define the shape of the filter as fxf (≈1 line)</span></span><br><span class="line">                        shape = (f, f)</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)</span><br><span class="line">                        </span><br><span class="line">    <span class="comment">### END CODE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == A_prev.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev</span><br></pre></td></tr></table></figure>
<h2 id="Convolutional-Neural-Networks-Application"><a href="#Convolutional-Neural-Networks-Application" class="headerlink" title="Convolutional Neural Networks: Application"></a>Convolutional Neural Networks: Application</h2><h3 id="1-0-Tensorflow-model"><a href="#1-0-Tensorflow-model" class="headerlink" title="1.0- Tensorflow model"></a>1.0- Tensorflow model</h3><p>导入包：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line"><span class="keyword">from</span> cnn_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>导入数据：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Loading the data (signs)</span></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br></pre></td></tr></table></figure></p>
<p>As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.<br><img src="https://upload-images.jianshu.io/upload_images/8636110-c4705e853cb55280.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of index below and re-run to see different examples.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of a picture</span></span><br><span class="line">index = <span class="number">6</span></span><br><span class="line">plt.imshow(X_train_orig[index])</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(np.squeeze(Y_train_orig[:, index])))</span><br></pre></td></tr></table></figure></p>
<p>In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.</p>
<p>To get started, let’s examine the shapes of your data.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of training examples = "</span> + str(X_train.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of test examples = "</span> + str(X_test.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_train shape: "</span> + str(X_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_train shape: "</span> + str(Y_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_test shape: "</span> + str(X_test.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_test shape: "</span> + str(Y_test.shape))</span><br><span class="line">conv_layers = &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="1-1-Create-placeholders"><a href="#1-1-Create-placeholders" class="headerlink" title="1.1- Create placeholders"></a>1.1- Create placeholders</h3><p>TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_H0, n_W0, n_C0, n_y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates the placeholders for the tensorflow session.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    n_H0 -- scalar, height of an input image</span></span><br><span class="line"><span class="string">    n_W0 -- scalar, width of an input image</span></span><br><span class="line"><span class="string">    n_C0 -- scalar, number of channels of the input</span></span><br><span class="line"><span class="string">    n_y -- scalar, number of classes</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float"</span></span><br><span class="line"><span class="string">    Y -- placeholder for the input labels, of shape [None, n_y] and dtype "float"</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈2 lines)</span></span><br><span class="line">    X = tf.placeholder(shape=[<span class="keyword">None</span>,n_H0,n_W0,n_C0],dtype=<span class="string">"float"</span>)</span><br><span class="line">    Y = tf.placeholder(shape=[<span class="keyword">None</span>,n_y],dtype=<span class="string">"float"</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure></p>
<h3 id="1-2-Initialize-parameters"><a href="#1-2-Initialize-parameters" class="headerlink" title="1.2- Initialize parameters"></a>1.2- Initialize parameters</h3><p>You will initialize weights/filters W1 and W2 using tf.contrib.layers.xavier_initializer(seed = 0). You don’t need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Initializes weight parameters to build a neural network with tensorflow. The shapes are:</span></span><br><span class="line"><span class="string">                        W1 : [4, 4, 3, 8]</span></span><br><span class="line"><span class="string">                        W2 : [2, 2, 8, 16]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary of tensors containing W1, W2</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                              <span class="comment"># so that your "random" numbers match ours</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 2 lines of code)</span></span><br><span class="line">    W1 = tf.get_variable(name=<span class="string">"W1"</span>, shape=[<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    W2 = tf.get_variable(name=<span class="string">"W2"</span>, shape=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">16</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>tf.Variable和tf.get_variable的区别：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_value=None, trainable=True, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None)</span><br><span class="line"></span><br><span class="line">tf.get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, partitioner=None, validate_shape=True, custom_getter=None)</span><br></pre></td></tr></table></figure></p>
<h3 id="1-3-Forward-propagation"><a href="#1-3-Forward-propagation" class="headerlink" title="1.3- Forward propagation"></a>1.3- Forward propagation</h3><p>In TensorFlow, there are built-in functions that carry out the convolution steps for you.</p>
<ul>
<li><strong>tf.nn.conv2d(X,W1, strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input X and a group of filters W1, this function convolves W1’s filters on X. The third input ([1,f,f,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). You can read the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">here</a></li>
<li><strong>tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window. You can read the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool" target="_blank" rel="noopener">here</a></li>
<li><strong>tf.nn.relu(Z1):</strong> computes the elementwise ReLU of Z1 (which can be any shape). You can read the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu" target="_blank" rel="noopener">here.</a></li>
<li><strong>tf.contrib.layers.flatten(P)</strong>: given an input P, this function flattens each example into a 1D vector it while maintaining the batch-size. It returns a flattened tensor with shape [batch_size, k]. You can read the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten" target="_blank" rel="noopener">here.</a></li>
<li><strong>tf.contrib.layers.fully_connected(F, num_outputs):</strong> given a the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected" target="_blank" rel="noopener">here.</a></li>
</ul>
<p>In the last function above (<code>tf.contrib.layers.fully_connected</code>), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters. </p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation for the model:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset placeholder, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "W2"</span></span><br><span class="line"><span class="string">                  the shapes are given in initialize_parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z3 -- the output of the last LINEAR unit</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary "parameters" </span></span><br><span class="line">    W1 = parameters[<span class="string">'W1'</span>]</span><br><span class="line">    W2 = parameters[<span class="string">'W2'</span>]</span><br><span class="line"></span><br><span class="line">    Z1 = tf.nn.conv2d(X,W1,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    A1 = tf.nn.relu(Z1)</span><br><span class="line">    P1 = tf.nn.max_pool(A1,ksize=[<span class="number">1</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    Z2 = tf.nn.conv2d(P1,W2,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    A2 = tf.nn.relu(Z2)</span><br><span class="line">    P2 = tf.nn.max_pool(A2,ksize=[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    P2 = tf.contrib.layers.flatter(P2)</span><br><span class="line">    Z2 = tf.contrib.layers.fully_connected(P2,<span class="number">6</span>,activation_fn=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="1-4-Compute-cost"><a href="#1-4-Compute-cost" class="headerlink" title="1.4- Compute cost"></a>1.4- Compute cost</h3><p>Implement the compute cost function below. You might find these two functions helpful:</p>
<ul>
<li>tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y): computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation here.</li>
<li>tf.reduce_mean: computes the mean of elements across dimensions of a tensor. Use this to sum the losses over all the examples to get the overall cost. You can check the full documentation here.</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(Z3, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector placeholder, same shape as Z3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - Tensor of the cost function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h2 id="1-4-Model"><a href="#1-4-Model" class="headerlink" title="1.4- Model"></a>1.4- Model</h2><p>Finally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset.</p>
<p>You have implemented random_mini_batches() in the Optimization programming assignment of course 2. Remember that this function returns a list of mini-batches.</p>
<p>The model below should:</p>
<ul>
<li>create placeholders</li>
<li>initialize parameters</li>
<li>forward propagate</li>
<li>compute the cost</li>
<li>create an optimizer</li>
</ul>
<p>Finally you will create a session and run a for loop for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, learning_rate = <span class="number">0.009</span>, num_epochs = <span class="number">100</span>, minibatch_size = <span class="number">64</span>, print_cost = True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a three-layer ConvNet in Tensorflow:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X_train -- training set, of shape (None, 64, 64, 3)</span></span><br><span class="line"><span class="string">    Y_train -- test set, of shape (None, n_y = 6)</span></span><br><span class="line"><span class="string">    X_test -- training set, of shape (None, 64, 64, 3)</span></span><br><span class="line"><span class="string">    Y_test -- test set, of shape (None, n_y = 6)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs of the optimization loop</span></span><br><span class="line"><span class="string">    minibatch_size -- size of a minibatch</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 100 epochs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    train_accuracy -- real number, accuracy on the train set (X_train)</span></span><br><span class="line"><span class="string">    test_accuracy -- real number, testing accuracy on the test set (X_test)</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    ops.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line">    seed = <span class="number">3</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape</span><br><span class="line">    n_y = Y_train.shape[<span class="number">1</span>]</span><br><span class="line">    costs = []</span><br><span class="line"></span><br><span class="line">    X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)</span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    Z3 = forward_propagation(X,parameters)</span><br><span class="line">    cost = compute_cost(Z3)</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">            minibatch_cost = <span class="number">0</span></span><br><span class="line">            num_minibatches = ini(m / minibatch_size)</span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                temp_cost, _ = sess.run([cost, optimizer], feed_dict=&#123;X:minibatch_X,Y:minibatch_Y&#125;)</span><br><span class="line">        <span class="keyword">if</span> print_cost == <span class="keyword">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, minibatch_cost))</span><br><span class="line">        <span class="keyword">if</span> print_cost == <span class="keyword">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line"></span><br><span class="line">    plt.plot(np.squeeze(costs))</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    predict_op = tf.argmax(Z3, <span class="number">1</span>)</span><br><span class="line">    correct_prediction = tf.equal(predict_op, tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    print(accuracy)</span><br><span class="line">    train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;)</span><br><span class="line">    test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;)</span><br><span class="line">    print(<span class="string">"Train Accuracy:"</span>, train_accuracy)</span><br><span class="line">    print(<span class="string">"Test Accuracy:"</span>, test_accuracy)</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br></pre></td></tr></table></figure>
<p>如果将之前的max_pool的ksize和strides都改为3x3，结果会得到优化，经过某次训练得到结果：<br><img src="https://upload-images.jianshu.io/upload_images/8636110-c77ae96f74c7b4d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>显然，结果过拟合了，即结果具有高方差。解决此问题的方法是，要么使用正则化，要么加大训练集的数量。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/19/deep-learningw9/" rel="next" title="第9周-机器学习ML策略(2)">
                <i class="fa fa-chevron-left"></i> 第9周-机器学习ML策略(2)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/22/deep-learningw11/" rel="prev" title="第11周-深度卷积神经网络">
                第11周-深度卷积神经网络 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="DesmonDay" />
          <p class="site-author-name" itemprop="name">DesmonDay</p>
           
              <p class="site-description motion-element" itemprop="description">主攻方向：NLP</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">110</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DesmonDay" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#计算机视觉"><span class="nav-number">1.</span> <span class="nav-text">计算机视觉</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积运算：边缘检测示例"><span class="nav-number">2.</span> <span class="nav-text">卷积运算：边缘检测示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#更多边缘检测内容"><span class="nav-number">3.</span> <span class="nav-text">更多边缘检测内容</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Vertical-and-Horizontal-Edge-Detection"><span class="nav-number">3.1.</span> <span class="nav-text">Vertical and Horizontal Edge Detection</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Padding"><span class="nav-number">4.</span> <span class="nav-text">Padding</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Valid-and-Same-convolutions"><span class="nav-number">4.1.</span> <span class="nav-text">Valid and Same convolutions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积步长：Strided-convolutions"><span class="nav-number">5.</span> <span class="nav-text">卷积步长：Strided convolutions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-of-convolutions"><span class="nav-number">5.1.</span> <span class="nav-text">Summary of convolutions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Technical-note-on-cross-correlation-vs-convolution"><span class="nav-number">5.2.</span> <span class="nav-text">Technical note on cross-correlation vs. convolution</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三维卷积：Convolutions-volumes"><span class="nav-number">6.</span> <span class="nav-text">三维卷积：Convolutions volumes</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#单层卷积网络：One-layer-of-a-convolutional-network"><span class="nav-number">7.</span> <span class="nav-text">单层卷积网络：One layer of a convolutional network</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-of-notation"><span class="nav-number">7.1.</span> <span class="nav-text">Summary of notation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简单卷积神经网络示例"><span class="nav-number">8.</span> <span class="nav-text">简单卷积神经网络示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#池化层：Pooling-Layer"><span class="nav-number">9.</span> <span class="nav-text">池化层：Pooling Layer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Max-Pooling-最大化池"><span class="nav-number">9.1.</span> <span class="nav-text">Max Pooling: 最大化池</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Average-Pooling-平均池化"><span class="nav-number">9.2.</span> <span class="nav-text">Average Pooling: 平均池化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">9.3.</span> <span class="nav-text">Summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络示例"><span class="nav-number">10.</span> <span class="nav-text">卷积神经网络示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么选择卷积"><span class="nav-number">11.</span> <span class="nav-text">为什么选择卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#参数共享和稀疏连接"><span class="nav-number">11.1.</span> <span class="nav-text">参数共享和稀疏连接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#整合"><span class="nav-number">11.2.</span> <span class="nav-text">整合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#本周作业"><span class="nav-number">12.</span> <span class="nav-text">本周作业</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolutional-Neural-Networks-Step-by-Step"><span class="nav-number">12.1.</span> <span class="nav-text">Convolutional Neural Networks: Step by Step</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Packages"><span class="nav-number">12.1.1.</span> <span class="nav-text">1- Packages</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Outline-of-the-Assignment"><span class="nav-number">12.1.2.</span> <span class="nav-text">2- Outline of the Assignment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Convolutional-Neural-Networks"><span class="nav-number">12.1.3.</span> <span class="nav-text">3- Convolutional Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-Zero-Padding"><span class="nav-number">12.1.3.1.</span> <span class="nav-text">3.1- Zero-Padding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-Single-step-of-convolution"><span class="nav-number">12.1.3.2.</span> <span class="nav-text">3.2- Single step of convolution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-Convolutional-Neural-Networks-Forward-pass"><span class="nav-number">12.1.3.3.</span> <span class="nav-text">3.3- Convolutional Neural Networks - Forward pass</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Pooling-layer"><span class="nav-number">12.1.4.</span> <span class="nav-text">4- Pooling layer</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Forward-Pooling"><span class="nav-number">12.1.4.1.</span> <span class="nav-text">4.1- Forward Pooling</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Backpropagation-in-convolutional-neural-networks"><span class="nav-number">12.1.5.</span> <span class="nav-text">5- Backpropagation in convolutional neural networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-Convolutional-layer-backward-pass"><span class="nav-number">12.1.5.1.</span> <span class="nav-text">5.1- Convolutional layer backward pass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-1-Computing-dA"><span class="nav-number">12.1.5.2.</span> <span class="nav-text">5.1.1- Computing dA:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-2-Computing-dW"><span class="nav-number">12.1.5.3.</span> <span class="nav-text">5.1.2- Computing dW:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-3-Computing-db"><span class="nav-number">12.1.5.4.</span> <span class="nav-text">5.1.3- Computing db:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-Pooling-layer-backward-pass"><span class="nav-number">12.1.6.</span> <span class="nav-text">5.2- Pooling layer - backward pass</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-1-Max-pooling-backward-pass"><span class="nav-number">12.1.6.1.</span> <span class="nav-text">5.2.1- Max pooling - backward pass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-2-Average-pooling-backward-pass"><span class="nav-number">12.1.6.2.</span> <span class="nav-text">5.2.2- Average pooling - backward pass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-3-Putting-it-together-Pooling-backward"><span class="nav-number">12.1.6.3.</span> <span class="nav-text">5.2.3- Putting it together: Pooling backward</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolutional-Neural-Networks-Application"><span class="nav-number">12.2.</span> <span class="nav-text">Convolutional Neural Networks: Application</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-0-Tensorflow-model"><span class="nav-number">12.2.1.</span> <span class="nav-text">1.0- Tensorflow model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Create-placeholders"><span class="nav-number">12.2.2.</span> <span class="nav-text">1.1- Create placeholders</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Initialize-parameters"><span class="nav-number">12.2.3.</span> <span class="nav-text">1.2- Initialize parameters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Forward-propagation"><span class="nav-number">12.2.4.</span> <span class="nav-text">1.3- Forward propagation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-Compute-cost"><span class="nav-number">12.2.5.</span> <span class="nav-text">1.4- Compute cost</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-Model"><span class="nav-number">12.3.</span> <span class="nav-text">1.4- Model</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DesmonDay</span>
</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>


