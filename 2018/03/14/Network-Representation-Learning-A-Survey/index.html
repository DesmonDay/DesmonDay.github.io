<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="paper," />





  <link rel="alternate" href="/atom.xml" title="DesmonDay's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="IntroductionIn the paper, the authors perform a thorough review of the current literature on network representation learning in the field of data mining and machine learning. In the past, a traditiona">
<meta name="keywords" content="paper">
<meta property="og:type" content="article">
<meta property="og:title" content="Reading report of Network Representation Learning(A Survey)">
<meta property="og:url" content="https://github.com/DesmonDay/2018/03/14/Network-Representation-Learning-A-Survey/index.html">
<meta property="og:site_name" content="DesmonDay&#39;s Blog">
<meta property="og:description" content="IntroductionIn the paper, the authors perform a thorough review of the current literature on network representation learning in the field of data mining and machine learning. In the past, a traditiona">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-a34a3ecd4b6ae9fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-c571f0c73b13e468.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-60f19c080dcec0cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/8636110-dffa6f3dc4db8c89.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-03-14T05:30:23.206Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reading report of Network Representation Learning(A Survey)">
<meta name="twitter:description" content="IntroductionIn the paper, the authors perform a thorough review of the current literature on network representation learning in the field of data mining and machine learning. In the past, a traditiona">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/8636110-a34a3ecd4b6ae9fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/DesmonDay/2018/03/14/Network-Representation-Learning-A-Survey/"/>





  <title>Reading report of Network Representation Learning(A Survey) | DesmonDay's Blog</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DesmonDay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一只小辣鸡的自我拯救之路</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/DesmonDay/2018/03/14/Network-Representation-Learning-A-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Desmon Day">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DesmonDay's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Reading report of Network Representation Learning(A Survey)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-14T13:13:47+08:00">
                2018-03-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>In the paper, the authors perform a thorough review of the current literature on network representation learning in the field of data mining and machine learning. In the past, a traditional discrete adjaceny matrix was usually used to represent a network, but which causes great time complexity and is not scalable to large-scale networks with millions of vertices. Besides, this kind of simple matrix ignores some important information like vertex attributes. Aiming to solve the above problems, a lot of researchers show greater reseach interest in the field of network representation learning(NRL). </p>
<p>The final target is to learn low-dimensional representations of network vertices, while preserving network structure and vertex content, etc. NRL has great potential in machine learning and data mining, but it is confronted with several key challenges: preserving local and global structure, preserving rich content on attributes, data sparsity and scalability.</p>
<h1 id="Notations-And-Definitions"><a href="#Notations-And-Definitions" class="headerlink" title="Notations And Definitions"></a>Notations And Definitions</h1><p>In this part, the authors give the definitions of important terminologies that are used in the later sections. Here I simply note down the terminologies, but will not give the concrete definitions here.</p>
<p>Information Network, First-order Proximity, Second-order Proximity and High-order Proximity, Intra-community Proximity, Network Representation Learning(NRL, the learned vertex representation should satisfy: low-dimensinoal, informative, continuous).</p>
<h1 id="Categorization-of-Network-Representation-Learning-Techniques"><a href="#Categorization-of-Network-Representation-Learning-Techniques" class="headerlink" title="Categorization of Network Representation Learning Techniques"></a>Categorization of Network Representation Learning Techniques</h1><p>In this section, the authors propose a taxonomy to categorize existing network representation learning techniques, as shown follows:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-a34a3ecd4b6ae9fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>The first layer is based on whether vertex labels are provided for learning, and they categorize into two groups: <strong>unsupervised network representation learning</strong>(no labeled vertices are available for learning vertex representations) and <strong>semi-supervised network representation learning</strong>(there exist some labeled vertices for representation learning).<br><img src="https://upload-images.jianshu.io/upload_images/8636110-c571f0c73b13e468.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>From algorithmic perspectives, there are four categories of existing NRL algorithms:<br>1) <strong>Matrix factorization based methods</strong>: Represent the connections between network vertices in the form of a matrix and use matrix factorization to obtain the embeddings. Bottleneck: memory intensive and computationally expensive.<br>2) <strong>Random walk based methods:</strong> Borrowing the idea of word representation learning, vertex representations are learned by using each vertex to predict its contexts.<br>Advantage:can be trained in an on-line manner, which means they are able to scale to large-scale information networks.<br>3) <strong>Edge modeling based methods</strong>: Directly learn the structure preserving vertex representations from vertex-vertex connections.<br>4) <strong>Deep learning based methods</strong>: To extract complex structure features and learn deep, the deep learning techniques are also applied to NRL.<br>Advantage: can capture nonlinearity in networks, but scalability and interpretability need to be further investigated.<br><img src="https://upload-images.jianshu.io/upload_images/8636110-60f19c080dcec0cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>There are four kinds of solutions used to <strong>optimize the objectives of the NRL algorithms</strong>: eigen decomposition, alternative optimization, gradient descent, stochastic gradient descent.</p>
<h1 id="Unsupervised-Network-Represetation-Learning"><a href="#Unsupervised-Network-Represetation-Learning" class="headerlink" title="Unsupervised Network Represetation Learning"></a>Unsupervised Network Represetation Learning</h1><p>In this section, the authors review unsupervised network representation learning methods and categorize them into two subsections. Here I will only mention the characteristics of the methods but will not refer to any algorithmic details. The algorithmic details should be detailed in the later paper readings.</p>
<h2 id="Unsupervised-Structure-Preserving-Network-Representation-Learning"><a href="#Unsupervised-Structure-Preserving-Network-Representation-Learning" class="headerlink" title="Unsupervised Structure Preserving Network Representation Learning"></a>Unsupervised Structure Preserving Network Representation Learning</h2><p>In this category, reseach efforts have been focused on designing various model to capture structure information conveyed by the original network as much as possible. The methods are as follows:</p>
<p><strong>Learning latent social dimensions</strong>: Community detection, including Modularity Maximization, Spectral Clustering, and Edge Clustering.<br><strong>DeepWalk</strong>: Generalize the idea of the Skip-Gram model.<br><strong>Large-scale Information Network Embedding</strong>: LINE, learns network vertex representations by explicitly modeling the first-order and the second-order proximity.<br><strong>GraRep</strong>: Following the idea of DeepWalk.<br><strong>Deep Neural Networks for Graph Representations</strong>: DNGR, utilizes the random surfing model to capture the contextual relatedness between each pair of vertices.<br><strong>Structural Deep Network Embedding</strong>: SDNE, uses a semi-supervised deep autoencoder model to capture non-linearity in network structure.<br><strong>node2vec</strong>: Biased random walk.<br><strong>M-NMF</strong>: See my blog <a href="https://desmonday.github.io/2018/02/24/Implementaion-of-M-NMF/" target="_blank" rel="noopener">https://desmonday.github.io/2018/02/24/Implementaion-of-M-NMF/</a><br>Summary: Most of the above unsupervised structure preserving NRL algorithms are matrix factorization based methods and random walk based methods.</p>
<h2 id="Unsupervised-Content-Augmented-Network-Representation-Learning"><a href="#Unsupervised-Content-Augmented-Network-Representation-Learning" class="headerlink" title="Unsupervised Content Augmented Network Representation Learning"></a>Unsupervised Content Augmented Network Representation Learning</h2><p>When we design the method of NRL, it would be better if we augment the vertex content information. NRL can be significantly improved if vertex attribute information is properly incorporated into the learning process. Some recent algorithms in this part:<br>TADW(Text-Associated DeepWalk), HSCA(Homophily, Structure, and Content Augmented Network Representation Learning), pRBM(Paired Restricted Boltzmann Machine).</p>
<h2 id="User-Profile-Preserving-Social-Network-Embedding-UPP-SNE"><a href="#User-Profile-Preserving-Social-Network-Embedding-UPP-SNE" class="headerlink" title="User Profile Preserving Social Network Embedding (UPP-SNE)"></a>User Profile Preserving Social Network Embedding (UPP-SNE)</h2><p>The user profile features are leveraged in UPP-SNE to enhance the embedding learning of users in social networks.</p>
<h1 id="Semi-supervised-Network-Representation-Learning"><a href="#Semi-supervised-Network-Representation-Learning" class="headerlink" title="Semi-supervised Network Representation Learning"></a>Semi-supervised Network Representation Learning</h1><p>Make use of vertex labels available in the network for seeking more effective vertex representations. </p>
<h2 id="Semi-Supervised-Structure-Preserving-NRL"><a href="#Semi-Supervised-Structure-Preserving-NRL" class="headerlink" title="Semi-Supervised Structure Preserving NRL"></a>Semi-Supervised Structure Preserving NRL</h2><p>DDRW(Discriminative Deep Random Walk): optimize the objective of DeepWalk and the L2-loss SVC classification objective.<br>MMDW(Max-Margin DeepWalk):couples the objective of the matrix factorization version DeepWalk with the multi-class SVM objective.<br>TLINE(Transductive LINE): a semisupervised extension of LINE.<br>GENE(Group Enhanced Network Embedding): integrates group(label) information with network structure in a probabilistic manner.</p>
<h2 id="Semi-Supervised-Content-Augmented-NRL"><a href="#Semi-Supervised-Content-Augmented-NRL" class="headerlink" title="Semi-Supervised Content Augmented NRL"></a>Semi-Supervised Content Augmented NRL</h2><p>TriDNR(Tri-Party Deep Network Representation): use a coupled neural network framework and learn vertex representations from network structure, vertex content and vertex labels.<br>LDE(Linked Document Embedding): learn representations for linked documents, modeling word-word-document relations, document-document relations, and document-label relations.<br>DMF(Discriminative Matrix Factorization): enforces the objective of TADW (14) with an empirical loss minimization of a linear classifier trained on labeled vertices.<br>Planetoid: Predictive labels and neighbors with embeddings transductively or inductively from data.<br>LANE(Label informed Attribute Network Embedding): learn vertex representations by embedding the network structure proximity, attribute affinity, and label proximity into a unified latent representation.</p>
<h1 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h1><p>There’s no doubt that information network plays an important role in our daily life. For example, social network(Recommendation, targeted advertising) and biological networks(facilitate new treatment), etc. In this section, the authors list several applications of network representation learning.</p>
<p>1) Vertex Classification: predict the labels of unlabeled vertices given a partially labeled network.<br>2) Link Prediction: infer the existence of new relationships or unknown interactions between pair of entities based on the currently observed links and their attributes.<br>3) Clustering: partition a network into a set of clusters, and effective representation learning can improve the clustering performance.<br>4) Visualization: visualize graphs from an information visualization perspective.<br>5) Recommendation: POI recommendation, using spatial-temporal embedding.<br>6) Knowledge Graph: a new type of data structure in database systems which encode structured information of billions of entities and their rich relations.</p>
<h1 id="Evaluation-for-Network-Representation-Learning"><a href="#Evaluation-for-Network-Representation-Learning" class="headerlink" title="Evaluation for Network Representation Learning"></a>Evaluation for Network Representation Learning</h1><p>In this section, the authors provide a summary of benchmark datasets for evaluating NRL. As the following table:<br><img src="https://upload-images.jianshu.io/upload_images/8636110-dffa6f3dc4db8c89.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>Later, they summarize several network analytic tasks of evaluation: Network reconstruction, vertex classification, vertex clustering, link prediction and visualization.</p>
<h1 id="My-Idea"><a href="#My-Idea" class="headerlink" title="My Idea"></a>My Idea</h1><p>In the big data era, to find a proper low-dimensional representation for network embedding is becoming important and imperative. According to the article, the current NRL algorithms stilll face following challenges: non-linearity, task-dependence, network dynamics, scalability and heterogeneity. Maybe I will focus more on network dynamics.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/paper/" rel="tag"><i class="fa fa-tag"></i> paper</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/13/1008-数组元素循环移位/" rel="next" title="PAT乙1008.数组元素循环移位">
                <i class="fa fa-chevron-left"></i> PAT乙1008.数组元素循环移位
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/14/1009-说反话/" rel="prev" title="PAT乙1009.说反话">
                PAT乙1009.说反话 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Desmon Day" />
          <p class="site-author-name" itemprop="name">Desmon Day</p>
           
              <p class="site-description motion-element" itemprop="description">主攻方向：大数据、社交网络</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">42</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DesmonDay" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Notations-And-Definitions"><span class="nav-number">2.</span> <span class="nav-text">Notations And Definitions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Categorization-of-Network-Representation-Learning-Techniques"><span class="nav-number">3.</span> <span class="nav-text">Categorization of Network Representation Learning Techniques</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Unsupervised-Network-Represetation-Learning"><span class="nav-number">4.</span> <span class="nav-text">Unsupervised Network Represetation Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Unsupervised-Structure-Preserving-Network-Representation-Learning"><span class="nav-number">4.1.</span> <span class="nav-text">Unsupervised Structure Preserving Network Representation Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Unsupervised-Content-Augmented-Network-Representation-Learning"><span class="nav-number">4.2.</span> <span class="nav-text">Unsupervised Content Augmented Network Representation Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#User-Profile-Preserving-Social-Network-Embedding-UPP-SNE"><span class="nav-number">4.3.</span> <span class="nav-text">User Profile Preserving Social Network Embedding (UPP-SNE)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Semi-supervised-Network-Representation-Learning"><span class="nav-number">5.</span> <span class="nav-text">Semi-supervised Network Representation Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Semi-Supervised-Structure-Preserving-NRL"><span class="nav-number">5.1.</span> <span class="nav-text">Semi-Supervised Structure Preserving NRL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Semi-Supervised-Content-Augmented-NRL"><span class="nav-number">5.2.</span> <span class="nav-text">Semi-Supervised Content Augmented NRL</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Applications"><span class="nav-number">6.</span> <span class="nav-text">Applications</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Evaluation-for-Network-Representation-Learning"><span class="nav-number">7.</span> <span class="nav-text">Evaluation for Network Representation Learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#My-Idea"><span class="nav-number">8.</span> <span class="nav-text">My Idea</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Desmon Day</span>
</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>

<script type="text/javascript" src="/js/src/love.js"></script>

